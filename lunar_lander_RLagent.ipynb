{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blt-tsp/ppo-agent/blob/main/lunar_lander_RLagent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMBcWrz527zG",
        "outputId": "681e085d-254f-4c7f-baf0-f6c80b9feb49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ray[rllib] in /usr/local/lib/python3.10/dist-packages (2.9.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray[rllib]) (8.1.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray[rllib]) (3.13.1)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray[rllib]) (4.19.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray[rllib]) (1.0.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ray[rllib]) (23.2)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray[rllib]) (3.20.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from ray[rllib]) (6.0.1)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray[rllib]) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray[rllib]) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ray[rllib]) (2.31.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from ray[rllib]) (1.5.3)\n",
            "Requirement already satisfied: tensorboardX>=1.9 in /usr/local/lib/python3.10/dist-packages (from ray[rllib]) (2.6.2.2)\n",
            "Requirement already satisfied: pyarrow>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from ray[rllib]) (10.0.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from ray[rllib]) (2023.6.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from ray[rllib]) (0.1.8)\n",
            "Requirement already satisfied: gymnasium==0.28.1 in /usr/local/lib/python3.10/dist-packages (from ray[rllib]) (0.28.1)\n",
            "Requirement already satisfied: lz4 in /usr/local/lib/python3.10/dist-packages (from ray[rllib]) (4.3.3)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from ray[rllib]) (0.19.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from ray[rllib]) (1.11.4)\n",
            "Requirement already satisfied: typer in /usr/local/lib/python3.10/dist-packages (from ray[rllib]) (0.9.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from ray[rllib]) (13.7.0)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium==0.28.1->ray[rllib]) (1.23.5)\n",
            "Requirement already satisfied: jax-jumpy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium==0.28.1->ray[rllib]) (1.0.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium==0.28.1->ray[rllib]) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium==0.28.1->ray[rllib]) (4.5.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium==0.28.1->ray[rllib]) (0.0.4)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[rllib]) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[rllib]) (2023.11.2)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[rllib]) (0.32.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[rllib]) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->ray[rllib]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->ray[rllib]) (2023.3.post1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ray[rllib]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ray[rllib]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ray[rllib]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ray[rllib]) (2023.11.17)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->ray[rllib]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->ray[rllib]) (2.16.1)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->ray[rllib]) (3.2.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->ray[rllib]) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->ray[rllib]) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->ray[rllib]) (2023.12.9)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->ray[rllib]) (1.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->ray[rllib]) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->ray[rllib]) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install 'ray[rllib]'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RU8_1YK3A7I",
        "outputId": "ec8ad571-b76e-46a4-e619-a4494ecd6ec7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.35.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.60.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etouYW9yDhPi",
        "outputId": "8c4d87bb-ff4c-4f00-cdb1-413f066f52c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "swig is already the newest version (4.0.2-1ubuntu1).\n",
            "cmake is already the newest version (3.22.1-1ubuntu1.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 24 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!apt install swig cmake"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrgrtyyrDmdy",
        "outputId": "32a8657a-7678-4a3f-d30a-6e6cce01a969"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: stable-baselines3==2.0.0a5 in /usr/local/lib/python3.10/dist-packages (from -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (2.0.0a5)\n",
            "Requirement already satisfied: swig in /usr/local/lib/python3.10/dist-packages (from -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 2)) (4.1.1.post1)\n",
            "Requirement already satisfied: gymnasium[box2d] in /usr/local/lib/python3.10/dist-packages (from -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 3)) (0.28.1)\n",
            "Requirement already satisfied: huggingface_sb3 in /usr/local/lib/python3.10/dist-packages (from -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 4)) (3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from stable-baselines3==2.0.0a5->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.11 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3==2.0.0a5->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (2.1.0+cu121)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable-baselines3==2.0.0a5->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (2.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable-baselines3==2.0.0a5->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (1.5.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable-baselines3==2.0.0a5->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (3.7.1)\n",
            "Requirement already satisfied: jax-jumpy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 3)) (1.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 3)) (4.5.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 3)) (0.0.4)\n",
            "Requirement already satisfied: box2d-py==2.3.5 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 3)) (2.3.5)\n",
            "Requirement already satisfied: pygame==2.1.3 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 3)) (2.1.3)\n",
            "Requirement already satisfied: huggingface-hub~=0.8 in /usr/local/lib/python3.10/dist-packages (from huggingface_sb3->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 4)) (0.20.1)\n",
            "Requirement already satisfied: pyyaml~=6.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_sb3->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 4)) (6.0.1)\n",
            "Requirement already satisfied: wasabi in /usr/local/lib/python3.10/dist-packages (from huggingface_sb3->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 4)) (1.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub~=0.8->huggingface_sb3->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 4)) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub~=0.8->huggingface_sb3->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 4)) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub~=0.8->huggingface_sb3->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 4)) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub~=0.8->huggingface_sb3->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 4)) (4.66.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub~=0.8->huggingface_sb3->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 4)) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->stable-baselines3==2.0.0a5->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->stable-baselines3==2.0.0a5->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->stable-baselines3==2.0.0a5->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->stable-baselines3==2.0.0a5->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (2.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==2.0.0a5->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==2.0.0a5->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==2.0.0a5->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (4.47.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==2.0.0a5->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==2.0.0a5->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==2.0.0a5->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==2.0.0a5->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3==2.0.0a5->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3==2.0.0a5->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11->stable-baselines3==2.0.0a5->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub~=0.8->huggingface_sb3->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 4)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub~=0.8->huggingface_sb3->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 4)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub~=0.8->huggingface_sb3->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 4)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub~=0.8->huggingface_sb3->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 4)) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11->stable-baselines3==2.0.0a5->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yx3k0Twf3KZp"
      },
      "source": [
        "# Understanding environnement\n",
        "## Tests and running some sequences from Lunar Lander env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ni2gR3Ua3G5u",
        "outputId": "15301dbf-7159-4195-de2d-3d902ba6d59f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Action : 2\n",
            "Action : 2\n",
            "Action : 0\n",
            "Action : 1\n",
            "Action : 0\n",
            "Action : 3\n",
            "Action : 1\n",
            "Action : 1\n",
            "Action : 0\n",
            "Action : 3\n"
          ]
        }
      ],
      "source": [
        "import gymnasium as gym\n",
        "\n",
        "# Creating and reset env\n",
        "\n",
        "env = gym.make(\"LunarLander-v2\")\n",
        "obs, info = env.reset()\n",
        "\n",
        "for _ in range(10):\n",
        "\n",
        "  # Taking random action from the space\n",
        "  action = env.action_space.sample()\n",
        "  print(\"Action :\", action)\n",
        "\n",
        "  # Carry out action in env and getting observations and bool if timeout or crash\n",
        "  obs, reward, timeout, crashed, info = env.step(action)\n",
        "\n",
        "  if timeout or crashed :\n",
        "    print(\"Reset\")\n",
        "    obs, info = env.reset()\n",
        "\n",
        "# don't forget to close env\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2kdArlr7AZ8",
        "outputId": "84bdaf2b-c9ef-4357-a36d-0778f465ac86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Observation space shape : (8,)\n",
            "Sample observation : [74.311905   69.35948    -0.20637977  0.83572084  2.883601   -1.0164675\n",
            "  0.09314613  0.7761887 ]\n"
          ]
        }
      ],
      "source": [
        "env = gym.make(\"LunarLander-v2\")\n",
        "env.reset()\n",
        "\n",
        "print(\"Observation space shape :\", env.observation_space.shape)\n",
        "print(\"Sample observation :\", env.observation_space.sample()) # Get a random observation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrGyW2DE7TNI"
      },
      "source": [
        " - observation vector :\n",
        "x, y, v_x, v_y, angle, v_angle, ?, ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8Fty50o7P_U",
        "outputId": "f468e3c6-13d5-4366-d395-2848eb8dfbb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Action space shape : 4\n",
            "Action space sample : 3\n"
          ]
        }
      ],
      "source": [
        "print(\"Action space shape :\", env.action_space.n)\n",
        "print(\"Action space sample :\", env.action_space.sample()) # Take a random action"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdBfiIoo7-Ib"
      },
      "source": [
        "- Action 0: Do nothing,\n",
        "- Action 1: Fire left orientation engine,\n",
        "- Action 2: Fire the main engine,\n",
        "- Action 3: Fire right orientation engine.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBq4W4lN97fa"
      },
      "outputs": [],
      "source": [
        "env.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dybYfi3-SCX"
      },
      "source": [
        "# Creating the agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQtxxQVgK3TP"
      },
      "source": [
        "## train.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "id": "4Q1oHPZmiQBt",
        "outputId": "8a68a065-51e2-483f-e673-51010bfd90c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gym in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Collecting gym\n",
            "  Downloading gym-0.26.2.tar.gz (721 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m721.7/721.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym) (1.23.5)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym) (0.0.8)\n",
            "Building wheels for collected packages: gym\n",
            "  Building wheel for gym (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.26.2-py3-none-any.whl size=827618 sha256=5e2fa4b60df847a13bb421ec64960f39fe735eb69759ec244fafd23adff4cd17\n",
            "  Stored in directory: /root/.cache/pip/wheels/b9/22/6d/3e7b32d98451b4cd9d12417052affbeeeea012955d437da1da\n",
            "Successfully built gym\n",
            "Installing collected packages: gym\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.2.0\n",
            "    Uninstalling gym-0.2.0:\n",
            "      Successfully uninstalled gym-0.2.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.0.6 requires gym<=0.25.2, but you have gym 0.26.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gym-0.26.2\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gym"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install --upgrade gym"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tz9u8wEXDTM6"
      },
      "outputs": [],
      "source": [
        "import ray\n",
        "from ray import tune\n",
        "from ray.rllib.algorithms import ppo\n",
        "from ray.tune.logger import pretty_print\n",
        "import gym\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "ray.shutdown()\n",
        "\n",
        "def train_ppo(env_name, reward_fn, lr, lbd, clip_param):\n",
        "  # Define environment and config\n",
        "  config = {\n",
        "      \"env\": env_name,\n",
        "      \"reward_fn\": reward_fn,\n",
        "      \"framework\": \"tf\",\n",
        "      \"num_workers\": 1,\n",
        "      \"lambda\": lbd,\n",
        "      \"clip_param\": clip_param,\n",
        "      \"lr\": lr,\n",
        "      \"gamma\": 0.99,\n",
        "      \"sgd_minibatch_size\": 256,\n",
        "      \"train_batch_size\": 2000,\n",
        "      \"num_iterations\": 100000,\n",
        "  }\n",
        "\n",
        "  # Agent training\n",
        "  results = tune.run(\n",
        "      \"PPO\",\n",
        "      name = \"my_experiment\",\n",
        "      config=config,\n",
        "      stop={\"timesteps_total\": 100000},\n",
        "      checkpoint_at_end=True,\n",
        "      metric=\"episode_reward_mean\",\n",
        "      mode=\"max\",\n",
        "  )\n",
        "\n",
        "  return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4P62ZDoQi3rq"
      },
      "outputs": [],
      "source": [
        "# Launch training in discrete space, using best hyperparams\n",
        "ray.init(num_cpus=2, num_gpus=0, ignore_reinit_error=True)\n",
        "res = train_ppo('LunarLander-v2', lr=3e-4, lbd=0.9, clip_param=0.2)\n",
        "ray.shutdown()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "id": "HEB-atxCLg62",
        "outputId": "45e283f8-9cb9-433d-d523-8921f6b66e2a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Checkpoint for Trial PPO_LunarLander-v2_17142_00000: Checkpoint(filesystem=local, path=/root/ray_results/my_experiment/PPO_LunarLander-v2_17142_00000_0_2024-01-07_10-54-11/checkpoint_000000)\n"
          ]
        }
      ],
      "source": [
        "# Extract results and plot learning curves\n",
        "%matplotlib inline\n",
        "\n",
        "def analyze_and_plot(results):\n",
        "  analysis = tune.ExperimentAnalysis(results.experiment_path)\n",
        "  dfs = analysis.trial_dataframes\n",
        "  threshold = 0\n",
        "\n",
        "  for trial, df in dfs.items():\n",
        "      episode_rewards_mean = df[\"episode_reward_mean\"]\n",
        "      plt.plot(episode_rewards_mean, '+', label=f\"Trial {trial}\", color='b')\n",
        "      plt.axhline(y=threshold, color='r', linestyle='--', label='Training objective')\n",
        "\n",
        "  plt.title(\"Learning Curve - Episode Reward Mean\")\n",
        "  plt.xlabel(\"Episode\")\n",
        "  plt.ylabel(\"Mean Reward\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  # Save the best checkpoint for each trial\n",
        "  for trial in analysis.trials:\n",
        "      best_checkpoint = analysis.get_best_checkpoint(trial, metric=\"episode_reward_mean\", mode=\"max\")\n",
        "      print(f\"Best Checkpoint for Trial {trial}: {best_checkpoint}\");\n",
        "\n",
        "# Learning curve - reward by episode\n",
        "analyze_and_plot(res)\n",
        "\n",
        "ray.shutdown()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fWhahsxIkRV0"
      },
      "outputs": [],
      "source": [
        "# restore a model from the last checkpoint\n",
        "trial = res.get_best_trial(\"episode_reward_mean\", \"max\")\n",
        "checkpoint = res.get_best_checkpoint(\n",
        "  trial,\n",
        "  \"training_iteration\",\n",
        "  \"max\",\n",
        ")\n",
        "ray.shutdown()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcSgJhZFoGim"
      },
      "source": [
        "## Rollout and visualize landing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "bXT6CjLU1-Nb",
        "outputId": "628089ec-f54c-4c73-8374-ceeb877876db"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "module 'gym' has no attribute 'spaces'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-d15bb7a69e14>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Perform a rollout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAlgorithm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ray/rllib/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Note: do not introduce unnecessary library dependencies here, e.g. gym.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# This file is imported from the tune module in order to register RLlib agents.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_env\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseEnv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexternal_env\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mExternalEnv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_agent_env\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultiAgentEnv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ray/rllib/env/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_env\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseEnv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv_context\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEnvContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexternal_env\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mExternalEnv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexternal_multi_agent_env\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mExternalMultiAgentEnv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_agent_env\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultiAgentEnv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ray/rllib/env/base_env.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgymnasium\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDeprecated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDeveloperAPI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPublicAPI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAgentID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEnvID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEnvType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultiEnvDict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ray/rllib/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moverride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPublicAPI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDeveloperAPI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprecation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeprecation_warning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFilter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_manager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFilterManager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m from ray.rllib.utils.framework import (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ray/rllib/utils/filter.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSMALL_NUMBER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorStructType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialization\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_serialize_ndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_deserialize_ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprecation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeprecation_warning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ray/rllib/utils/serialization.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mold_gym_text_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mold_gym\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mold_gym_text_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_gym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspaces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Text\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'gym' has no attribute 'spaces'"
          ]
        }
      ],
      "source": [
        "# Perform a rollout\n",
        "from ray.rllib.algorithms import Algorithm\n",
        "import ray\n",
        "import gym\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "ray.shutdown()\n",
        "\n",
        "def rollout_display(env_name, checkpoint):\n",
        "\n",
        "  ray.init(num_cpus=2, ignore_reinit_error=True)\n",
        "  checkpoint_path = checkpoint.to_directory()\n",
        "  config = {\n",
        "      \"env\": env_name,\n",
        "      \"framework\": \"tf\",\n",
        "      \"num_workers\": 1,\n",
        "      \"lambda\": 0.95,\n",
        "      \"clip_param\": 0.1,\n",
        "      \"lr\": 5e-4,\n",
        "      \"gamma\": 0.99,\n",
        "      \"sgd_minibatch_size\": 256,\n",
        "      \"train_batch_size\": 2000,\n",
        "      \"num_iterations\": 100000,\n",
        "  }\n",
        "\n",
        "  results = tune.run(\n",
        "      \"PPO\",\n",
        "      config=config,\n",
        "      restore=checkpoint_path,\n",
        "      stop={\"timesteps_total\": 100000},\n",
        "      num_samples=1,\n",
        "  )\n",
        "\n",
        "  agent = Algorithm.from_checkpoint(results.get_last_checkpoint())\n",
        "  return agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MnUtXj6QjAO2"
      },
      "outputs": [],
      "source": [
        "# Generating agent\n",
        "agent = rollout_display('LunarLander-v2', checkpoint)\n",
        "ray.shutdown()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "-dA9qko2eGYF",
        "outputId": "fd9a99c0-31c4-4265-8f00-d05161292ee9"
      },
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'Monitor' from 'gym.wrappers' (/usr/local/lib/python3.10/dist-packages/gym/wrappers/__init__.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d8f9a8c6e972>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrappers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMonitor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHTML\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrecord_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'landing_video'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'Monitor' from 'gym.wrappers' (/usr/local/lib/python3.10/dist-packages/gym/wrappers/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import gym\n",
        "from gym.wrappers import Monitor              # Need to downgrade gym, deprecated\n",
        "from IPython.display import HTML\n",
        "\n",
        "def record_video(env_name, agent, video_name='landing_video'):\n",
        "    env = gym.make(env_name, render_mode='rgb_array')\n",
        "\n",
        "    # Wrap the environment with the Monitor to record the video\n",
        "    env = Monitor(env, video_name, force=True, video_callable=lambda episode: True)\n",
        "\n",
        "    observation = env.reset()\n",
        "    done = False\n",
        "\n",
        "    while not done:\n",
        "        frame = env.render(mode='rgb_array')\n",
        "        action = agent.compute_single_action(observation)\n",
        "        observation, reward, done, _ = env.step(action)\n",
        "\n",
        "    env.close()\n",
        "\n",
        "    # Display the recorded video\n",
        "    html = env.get_video_html()\n",
        "    HTML(html)\n",
        "\n",
        "# Generating video of landing using trained agent\n",
        "record_video(env_name='LunarLander-v2', agent=agent)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoRi0M7YycDu"
      },
      "source": [
        "# Hyperparameters tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WNT6_Gkl3zE",
        "outputId": "9892d1eb-c209-47fd-f8e6-b64a00559620"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-01-07 11:08:07,162\tINFO worker.py:1558 -- Calling ray.init() again after it has already been called.\n",
            "2024-01-07 11:08:07,170\tINFO tune.py:592 -- [output] This will use the new output engine with verbosity 2. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n",
            "2024-01-07 11:08:07,195\tWARNING tune.py:916 -- AIR_VERBOSITY is set, ignoring passed-in ProgressReporter for now.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------------------------------------------------+\n",
            "| Configuration for experiment     train_2024-01-07_11-08-07   |\n",
            "+--------------------------------------------------------------+\n",
            "| Search algorithm                 BasicVariantGenerator       |\n",
            "| Scheduler                        FIFOScheduler               |\n",
            "| Number of trials                 81                          |\n",
            "+--------------------------------------------------------------+\n",
            "\n",
            "View detailed results here: /content/tune_results/train_2024-01-07_11-08-07\n",
            "To visualize your results with TensorBoard, run: `tensorboard --logdir /content/tune_results/train_2024-01-07_11-08-07`\n",
            "\n",
            "Trial status: 16 PENDING\n",
            "Current time: 2024-01-07 11:08:07. Total running time: 0s\n",
            "Logical resource usage: 0/2 CPUs, 0/1 GPUs\n",
            "+-----------------------------------------------------------------+\n",
            "| Trial name          status       lambda     clip_param       lr |\n",
            "+-----------------------------------------------------------------+\n",
            "| train_091b2_00000   PENDING         0.8            0.1   0.0001 |\n",
            "| train_091b2_00001   PENDING         0.8            0.2   0.0001 |\n",
            "| train_091b2_00002   PENDING         0.8            0.3   0.0001 |\n",
            "| train_091b2_00003   PENDING         0.9            0.1   0.0001 |\n",
            "| train_091b2_00004   PENDING         0.9            0.2   0.0001 |\n",
            "| train_091b2_00005   PENDING         0.9            0.3   0.0001 |\n",
            "| train_091b2_00006   PENDING         1              0.1   0.0001 |\n",
            "| train_091b2_00007   PENDING         1              0.2   0.0001 |\n",
            "| train_091b2_00008   PENDING         1              0.3   0.0001 |\n",
            "| train_091b2_00009   PENDING         0.8            0.1   0.0003 |\n",
            "| train_091b2_00010   PENDING         0.8            0.2   0.0003 |\n",
            "| train_091b2_00011   PENDING         0.8            0.3   0.0003 |\n",
            "| train_091b2_00012   PENDING         0.9            0.1   0.0003 |\n",
            "| train_091b2_00013   PENDING         0.9            0.2   0.0003 |\n",
            "| train_091b2_00014   PENDING         0.9            0.3   0.0003 |\n",
            "| train_091b2_00015   PENDING         1              0.1   0.0003 |\n",
            "+-----------------------------------------------------------------+\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-01-07 11:08:13,531\tERROR tune_controller.py:1374 -- Trial task failed for trial train_091b2_00000\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
            "    result = ray.get(future)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2624, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=28148, ip=172.28.0.12, actor_id=bc18b9e1f0c7e38541e7125601000000, repr=train)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 342, in train\n",
            "    raise skipped from exception_cause(skipped)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/_internal/util.py\", line 88, in run\n",
            "    self._ret = self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 115, in <lambda>\n",
            "    training_func=lambda: self._trainable_func(self.config),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 332, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"<ipython-input-21-4cf143c8e7dd>\", line 13, in train\n",
            "AttributeError: 'dict' object has no attribute 'training_iteration'\n",
            "2024-01-07 11:08:13,682\tERROR tune_controller.py:1374 -- Trial task failed for trial train_091b2_00001\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
            "    result = ray.get(future)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2624, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=28150, ip=172.28.0.12, actor_id=05a9fafdd358c0fd5f633c8e01000000, repr=train)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 342, in train\n",
            "    raise skipped from exception_cause(skipped)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/_internal/util.py\", line 88, in run\n",
            "    self._ret = self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 115, in <lambda>\n",
            "    training_func=lambda: self._trainable_func(self.config),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 332, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"<ipython-input-21-4cf143c8e7dd>\", line 13, in train\n",
            "AttributeError: 'dict' object has no attribute 'training_iteration'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial train_091b2_00000 started with configuration:\n",
            "+-------------------------------------------+\n",
            "| Trial train_091b2_00000 config            |\n",
            "+-------------------------------------------+\n",
            "| clip_param                            0.1 |\n",
            "| lambda                                0.8 |\n",
            "| lr                                 0.0001 |\n",
            "| stop_iteration                         10 |\n",
            "+-------------------------------------------+\n",
            "\n",
            "Trial train_091b2_00000 errored after 0 iterations at 2024-01-07 11:08:13. Total running time: 6s\n",
            "Error file: /content/tune_results/train_2024-01-07_11-08-07/train_091b2_00000_0_clip_param=0.1000,lambda=0.8000,lr=0.0001_2024-01-07_11-08-07/error.txt\n",
            "\n",
            "Trial train_091b2_00001 started with configuration:\n",
            "+-------------------------------------------+\n",
            "| Trial train_091b2_00001 config            |\n",
            "+-------------------------------------------+\n",
            "| clip_param                            0.2 |\n",
            "| lambda                                0.8 |\n",
            "| lr                                 0.0001 |\n",
            "| stop_iteration                         10 |\n",
            "+-------------------------------------------+\n",
            "\n",
            "Trial train_091b2_00001 errored after 0 iterations at 2024-01-07 11:08:13. Total running time: 6s\n",
            "Error file: /content/tune_results/train_2024-01-07_11-08-07/train_091b2_00001_1_clip_param=0.2000,lambda=0.8000,lr=0.0001_2024-01-07_11-08-07/error.txt\n",
            "\n",
            "Trial train_091b2_00002 started with configuration:\n",
            "+-------------------------------------------+\n",
            "| Trial train_091b2_00002 config            |\n",
            "+-------------------------------------------+\n",
            "| clip_param                            0.3 |\n",
            "| lambda                                0.8 |\n",
            "| lr                                 0.0001 |\n",
            "| stop_iteration                         10 |\n",
            "+-------------------------------------------+\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-01-07 11:08:19,509\tERROR tune_controller.py:1374 -- Trial task failed for trial train_091b2_00002\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
            "    result = ray.get(future)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2624, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=28283, ip=172.28.0.12, actor_id=26d74e33c46e201a7e30c97101000000, repr=train)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 342, in train\n",
            "    raise skipped from exception_cause(skipped)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/_internal/util.py\", line 88, in run\n",
            "    self._ret = self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 115, in <lambda>\n",
            "    training_func=lambda: self._trainable_func(self.config),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 332, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"<ipython-input-21-4cf143c8e7dd>\", line 13, in train\n",
            "AttributeError: 'dict' object has no attribute 'training_iteration'\n",
            "2024-01-07 11:08:19,560\tERROR tune_controller.py:1374 -- Trial task failed for trial train_091b2_00003\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
            "    result = ray.get(future)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2624, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=28286, ip=172.28.0.12, actor_id=89db4e39cb45cee12f4a874e01000000, repr=train)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 342, in train\n",
            "    raise skipped from exception_cause(skipped)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/_internal/util.py\", line 88, in run\n",
            "    self._ret = self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 115, in <lambda>\n",
            "    training_func=lambda: self._trainable_func(self.config),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 332, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"<ipython-input-21-4cf143c8e7dd>\", line 13, in train\n",
            "AttributeError: 'dict' object has no attribute 'training_iteration'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial train_091b2_00002 errored after 0 iterations at 2024-01-07 11:08:19. Total running time: 12s\n",
            "Error file: /content/tune_results/train_2024-01-07_11-08-07/train_091b2_00002_2_clip_param=0.3000,lambda=0.8000,lr=0.0001_2024-01-07_11-08-07/error.txt\n",
            "\n",
            "Trial train_091b2_00003 started with configuration:\n",
            "+-------------------------------------------+\n",
            "| Trial train_091b2_00003 config            |\n",
            "+-------------------------------------------+\n",
            "| clip_param                            0.1 |\n",
            "| lambda                                0.9 |\n",
            "| lr                                 0.0001 |\n",
            "| stop_iteration                         10 |\n",
            "+-------------------------------------------+\n",
            "\n",
            "Trial train_091b2_00003 errored after 0 iterations at 2024-01-07 11:08:19. Total running time: 12s\n",
            "Error file: /content/tune_results/train_2024-01-07_11-08-07/train_091b2_00003_3_clip_param=0.1000,lambda=0.9000,lr=0.0001_2024-01-07_11-08-07/error.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-01-07 11:08:24,515\tERROR tune_controller.py:1374 -- Trial task failed for trial train_091b2_00004\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
            "    result = ray.get(future)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2624, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=28409, ip=172.28.0.12, actor_id=dd5ca22983059323be1c1cbc01000000, repr=train)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 342, in train\n",
            "    raise skipped from exception_cause(skipped)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/_internal/util.py\", line 88, in run\n",
            "    self._ret = self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 115, in <lambda>\n",
            "    training_func=lambda: self._trainable_func(self.config),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 332, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"<ipython-input-21-4cf143c8e7dd>\", line 13, in train\n",
            "AttributeError: 'dict' object has no attribute 'training_iteration'\n",
            "2024-01-07 11:08:24,644\tERROR tune_controller.py:1374 -- Trial task failed for trial train_091b2_00005\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
            "    result = ray.get(future)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2624, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=28412, ip=172.28.0.12, actor_id=317f5ba6e54ca72f3fcec7e701000000, repr=train)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 342, in train\n",
            "    raise skipped from exception_cause(skipped)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/_internal/util.py\", line 88, in run\n",
            "    self._ret = self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 115, in <lambda>\n",
            "    training_func=lambda: self._trainable_func(self.config),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 332, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"<ipython-input-21-4cf143c8e7dd>\", line 13, in train\n",
            "AttributeError: 'dict' object has no attribute 'training_iteration'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial train_091b2_00004 started with configuration:\n",
            "+-------------------------------------------+\n",
            "| Trial train_091b2_00004 config            |\n",
            "+-------------------------------------------+\n",
            "| clip_param                            0.2 |\n",
            "| lambda                                0.9 |\n",
            "| lr                                 0.0001 |\n",
            "| stop_iteration                         10 |\n",
            "+-------------------------------------------+\n",
            "\n",
            "Trial train_091b2_00004 errored after 0 iterations at 2024-01-07 11:08:24. Total running time: 17s\n",
            "Error file: /content/tune_results/train_2024-01-07_11-08-07/train_091b2_00004_4_clip_param=0.2000,lambda=0.9000,lr=0.0001_2024-01-07_11-08-07/error.txt\n",
            "\n",
            "Trial train_091b2_00005 started with configuration:\n",
            "+-------------------------------------------+\n",
            "| Trial train_091b2_00005 config            |\n",
            "+-------------------------------------------+\n",
            "| clip_param                            0.3 |\n",
            "| lambda                                0.9 |\n",
            "| lr                                 0.0001 |\n",
            "| stop_iteration                         10 |\n",
            "+-------------------------------------------+\n",
            "\n",
            "Trial train_091b2_00005 errored after 0 iterations at 2024-01-07 11:08:24. Total running time: 17s\n",
            "Error file: /content/tune_results/train_2024-01-07_11-08-07/train_091b2_00005_5_clip_param=0.3000,lambda=0.9000,lr=0.0001_2024-01-07_11-08-07/error.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-01-07 11:08:32,215\tERROR tune_controller.py:1374 -- Trial task failed for trial train_091b2_00006\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
            "    result = ray.get(future)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2624, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=28540, ip=172.28.0.12, actor_id=0eb72cf35cc456401cfcb66c01000000, repr=train)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 342, in train\n",
            "    raise skipped from exception_cause(skipped)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/_internal/util.py\", line 88, in run\n",
            "    self._ret = self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 115, in <lambda>\n",
            "    training_func=lambda: self._trainable_func(self.config),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 332, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"<ipython-input-21-4cf143c8e7dd>\", line 13, in train\n",
            "AttributeError: 'dict' object has no attribute 'training_iteration'\n",
            "2024-01-07 11:08:32,320\tERROR tune_controller.py:1374 -- Trial task failed for trial train_091b2_00007\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
            "    result = ray.get(future)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2624, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=28546, ip=172.28.0.12, actor_id=09f81cf8cb7bd8623376ad2d01000000, repr=train)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 342, in train\n",
            "    raise skipped from exception_cause(skipped)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/_internal/util.py\", line 88, in run\n",
            "    self._ret = self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 115, in <lambda>\n",
            "    training_func=lambda: self._trainable_func(self.config),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 332, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"<ipython-input-21-4cf143c8e7dd>\", line 13, in train\n",
            "AttributeError: 'dict' object has no attribute 'training_iteration'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial train_091b2_00006 started with configuration:\n",
            "+-------------------------------------------+\n",
            "| Trial train_091b2_00006 config            |\n",
            "+-------------------------------------------+\n",
            "| clip_param                            0.1 |\n",
            "| lambda                                  1 |\n",
            "| lr                                 0.0001 |\n",
            "| stop_iteration                         10 |\n",
            "+-------------------------------------------+\n",
            "\n",
            "Trial train_091b2_00006 errored after 0 iterations at 2024-01-07 11:08:32. Total running time: 25s\n",
            "Error file: /content/tune_results/train_2024-01-07_11-08-07/train_091b2_00006_6_clip_param=0.1000,lambda=1.0000,lr=0.0001_2024-01-07_11-08-07/error.txt\n",
            "\n",
            "Trial train_091b2_00007 started with configuration:\n",
            "+-------------------------------------------+\n",
            "| Trial train_091b2_00007 config            |\n",
            "+-------------------------------------------+\n",
            "| clip_param                            0.2 |\n",
            "| lambda                                  1 |\n",
            "| lr                                 0.0001 |\n",
            "| stop_iteration                         10 |\n",
            "+-------------------------------------------+\n",
            "\n",
            "Trial train_091b2_00007 errored after 0 iterations at 2024-01-07 11:08:32. Total running time: 25s\n",
            "Error file: /content/tune_results/train_2024-01-07_11-08-07/train_091b2_00007_7_clip_param=0.2000,lambda=1.0000,lr=0.0001_2024-01-07_11-08-07/error.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-01-07 11:08:36,704\tERROR tune_controller.py:1374 -- Trial task failed for trial train_091b2_00008\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
            "    result = ray.get(future)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2624, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=28647, ip=172.28.0.12, actor_id=5666aad0eecb2f580a9167a301000000, repr=train)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 342, in train\n",
            "    raise skipped from exception_cause(skipped)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/_internal/util.py\", line 88, in run\n",
            "    self._ret = self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 115, in <lambda>\n",
            "    training_func=lambda: self._trainable_func(self.config),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 332, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"<ipython-input-21-4cf143c8e7dd>\", line 13, in train\n",
            "AttributeError: 'dict' object has no attribute 'training_iteration'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial train_091b2_00008 started with configuration:\n",
            "+-------------------------------------------+\n",
            "| Trial train_091b2_00008 config            |\n",
            "+-------------------------------------------+\n",
            "| clip_param                            0.3 |\n",
            "| lambda                                  1 |\n",
            "| lr                                 0.0001 |\n",
            "| stop_iteration                         10 |\n",
            "+-------------------------------------------+\n",
            "\n",
            "Trial train_091b2_00008 errored after 0 iterations at 2024-01-07 11:08:36. Total running time: 29s\n",
            "Error file: /content/tune_results/train_2024-01-07_11-08-07/train_091b2_00008_8_clip_param=0.3000,lambda=1.0000,lr=0.0001_2024-01-07_11-08-07/error.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-01-07 11:08:37,480\tERROR tune_controller.py:1374 -- Trial task failed for trial train_091b2_00009\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
            "    result = ray.get(future)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2624, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=28676, ip=172.28.0.12, actor_id=22c91010d9228a16d301fcc201000000, repr=train)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 342, in train\n",
            "    raise skipped from exception_cause(skipped)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/_internal/util.py\", line 88, in run\n",
            "    self._ret = self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 115, in <lambda>\n",
            "    training_func=lambda: self._trainable_func(self.config),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 332, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"<ipython-input-21-4cf143c8e7dd>\", line 13, in train\n",
            "AttributeError: 'dict' object has no attribute 'training_iteration'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial train_091b2_00009 started with configuration:\n",
            "+-------------------------------------------+\n",
            "| Trial train_091b2_00009 config            |\n",
            "+-------------------------------------------+\n",
            "| clip_param                            0.1 |\n",
            "| lambda                                0.8 |\n",
            "| lr                                 0.0003 |\n",
            "| stop_iteration                         10 |\n",
            "+-------------------------------------------+\n",
            "\n",
            "Trial train_091b2_00009 errored after 0 iterations at 2024-01-07 11:08:37. Total running time: 30s\n",
            "Error file: /content/tune_results/train_2024-01-07_11-08-07/train_091b2_00009_9_clip_param=0.1000,lambda=0.8000,lr=0.0003_2024-01-07_11-08-07/error.txt\n",
            "\n",
            "Trial status: 10 ERROR | 16 PENDING\n",
            "Current time: 2024-01-07 11:08:37. Total running time: 30s\n",
            "Logical resource usage: 0/2 CPUs, 0/1 GPUs\n",
            "+-----------------------------------------------------------------+\n",
            "| Trial name          status       lambda     clip_param       lr |\n",
            "+-----------------------------------------------------------------+\n",
            "| train_091b2_00010   PENDING         0.8            0.2   0.0003 |\n",
            "| train_091b2_00011   PENDING         0.8            0.3   0.0003 |\n",
            "| train_091b2_00012   PENDING         0.9            0.1   0.0003 |\n",
            "| train_091b2_00013   PENDING         0.9            0.2   0.0003 |\n",
            "| train_091b2_00014   PENDING         0.9            0.3   0.0003 |\n",
            "| train_091b2_00000   ERROR           0.8            0.1   0.0001 |\n",
            "| train_091b2_00001   ERROR           0.8            0.2   0.0001 |\n",
            "| train_091b2_00002   ERROR           0.8            0.3   0.0001 |\n",
            "| train_091b2_00003   ERROR           0.9            0.1   0.0001 |\n",
            "| train_091b2_00004   ERROR           0.9            0.2   0.0001 |\n",
            "+-----------------------------------------------------------------+\n",
            "11 more PENDING, 5 more ERROR\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-01-07 11:08:41,966\tERROR tune_controller.py:1374 -- Trial task failed for trial train_091b2_00010\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
            "    result = ray.get(future)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2624, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=28773, ip=172.28.0.12, actor_id=1caaf26a6833f7dfb2f083bd01000000, repr=train)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 342, in train\n",
            "    raise skipped from exception_cause(skipped)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/_internal/util.py\", line 88, in run\n",
            "    self._ret = self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 115, in <lambda>\n",
            "    training_func=lambda: self._trainable_func(self.config),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 332, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"<ipython-input-21-4cf143c8e7dd>\", line 13, in train\n",
            "AttributeError: 'dict' object has no attribute 'training_iteration'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial train_091b2_00010 started with configuration:\n",
            "+-------------------------------------------+\n",
            "| Trial train_091b2_00010 config            |\n",
            "+-------------------------------------------+\n",
            "| clip_param                            0.2 |\n",
            "| lambda                                0.8 |\n",
            "| lr                                 0.0003 |\n",
            "| stop_iteration                         10 |\n",
            "+-------------------------------------------+\n",
            "\n",
            "Trial train_091b2_00010 errored after 0 iterations at 2024-01-07 11:08:41. Total running time: 34s\n",
            "Error file: /content/tune_results/train_2024-01-07_11-08-07/train_091b2_00010_10_clip_param=0.2000,lambda=0.8000,lr=0.0003_2024-01-07_11-08-07/error.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-01-07 11:08:46,127\tERROR tune_controller.py:1374 -- Trial task failed for trial train_091b2_00011\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
            "    result = ray.get(future)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2624, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=28802, ip=172.28.0.12, actor_id=d811655d7bde491f62f3e99401000000, repr=train)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 342, in train\n",
            "    raise skipped from exception_cause(skipped)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/_internal/util.py\", line 88, in run\n",
            "    self._ret = self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 115, in <lambda>\n",
            "    training_func=lambda: self._trainable_func(self.config),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 332, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"<ipython-input-21-4cf143c8e7dd>\", line 13, in train\n",
            "AttributeError: 'dict' object has no attribute 'training_iteration'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial train_091b2_00011 started with configuration:\n",
            "+-------------------------------------------+\n",
            "| Trial train_091b2_00011 config            |\n",
            "+-------------------------------------------+\n",
            "| clip_param                            0.3 |\n",
            "| lambda                                0.8 |\n",
            "| lr                                 0.0003 |\n",
            "| stop_iteration                         10 |\n",
            "+-------------------------------------------+\n",
            "\n",
            "Trial train_091b2_00011 errored after 0 iterations at 2024-01-07 11:08:46. Total running time: 38s\n",
            "Error file: /content/tune_results/train_2024-01-07_11-08-07/train_091b2_00011_11_clip_param=0.3000,lambda=0.8000,lr=0.0003_2024-01-07_11-08-07/error.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-01-07 11:08:47,692\tERROR tune_controller.py:1374 -- Trial task failed for trial train_091b2_00012\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
            "    result = ray.get(future)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2624, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=28898, ip=172.28.0.12, actor_id=2a79daadf7869ca512cf751501000000, repr=train)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 342, in train\n",
            "    raise skipped from exception_cause(skipped)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/_internal/util.py\", line 88, in run\n",
            "    self._ret = self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 115, in <lambda>\n",
            "    training_func=lambda: self._trainable_func(self.config),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 332, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"<ipython-input-21-4cf143c8e7dd>\", line 13, in train\n",
            "AttributeError: 'dict' object has no attribute 'training_iteration'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial train_091b2_00012 started with configuration:\n",
            "+-------------------------------------------+\n",
            "| Trial train_091b2_00012 config            |\n",
            "+-------------------------------------------+\n",
            "| clip_param                            0.1 |\n",
            "| lambda                                0.9 |\n",
            "| lr                                 0.0003 |\n",
            "| stop_iteration                         10 |\n",
            "+-------------------------------------------+\n",
            "\n",
            "Trial train_091b2_00012 errored after 0 iterations at 2024-01-07 11:08:47. Total running time: 40s\n",
            "Error file: /content/tune_results/train_2024-01-07_11-08-07/train_091b2_00012_12_clip_param=0.1000,lambda=0.9000,lr=0.0003_2024-01-07_11-08-07/error.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-01-07 11:08:51,497\tERROR tune_controller.py:1374 -- Trial task failed for trial train_091b2_00013\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
            "    result = ray.get(future)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2624, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=28973, ip=172.28.0.12, actor_id=90347ea0669409b9c4e1baf101000000, repr=train)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 342, in train\n",
            "    raise skipped from exception_cause(skipped)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/_internal/util.py\", line 88, in run\n",
            "    self._ret = self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 115, in <lambda>\n",
            "    training_func=lambda: self._trainable_func(self.config),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 332, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"<ipython-input-21-4cf143c8e7dd>\", line 13, in train\n",
            "AttributeError: 'dict' object has no attribute 'training_iteration'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial train_091b2_00013 started with configuration:\n",
            "+-------------------------------------------+\n",
            "| Trial train_091b2_00013 config            |\n",
            "+-------------------------------------------+\n",
            "| clip_param                            0.2 |\n",
            "| lambda                                0.9 |\n",
            "| lr                                 0.0003 |\n",
            "| stop_iteration                         10 |\n",
            "+-------------------------------------------+\n",
            "\n",
            "Trial train_091b2_00013 errored after 0 iterations at 2024-01-07 11:08:51. Total running time: 44s\n",
            "Error file: /content/tune_results/train_2024-01-07_11-08-07/train_091b2_00013_13_clip_param=0.2000,lambda=0.9000,lr=0.0003_2024-01-07_11-08-07/error.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-01-07 11:08:53,091\tERROR tune_controller.py:1374 -- Trial task failed for trial train_091b2_00014\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
            "    result = ray.get(future)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2624, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=29029, ip=172.28.0.12, actor_id=f384f0dce89aec50bc98859d01000000, repr=train)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 342, in train\n",
            "    raise skipped from exception_cause(skipped)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/_internal/util.py\", line 88, in run\n",
            "    self._ret = self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 115, in <lambda>\n",
            "    training_func=lambda: self._trainable_func(self.config),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 332, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"<ipython-input-21-4cf143c8e7dd>\", line 13, in train\n",
            "AttributeError: 'dict' object has no attribute 'training_iteration'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial train_091b2_00014 started with configuration:\n",
            "+-------------------------------------------+\n",
            "| Trial train_091b2_00014 config            |\n",
            "+-------------------------------------------+\n",
            "| clip_param                            0.3 |\n",
            "| lambda                                0.9 |\n",
            "| lr                                 0.0003 |\n",
            "| stop_iteration                         10 |\n",
            "+-------------------------------------------+\n",
            "\n",
            "Trial train_091b2_00014 errored after 0 iterations at 2024-01-07 11:08:53. Total running time: 45s\n",
            "Error file: /content/tune_results/train_2024-01-07_11-08-07/train_091b2_00014_14_clip_param=0.3000,lambda=0.9000,lr=0.0003_2024-01-07_11-08-07/error.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-01-07 11:08:56,390\tERROR tune_controller.py:1374 -- Trial task failed for trial train_091b2_00015\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
            "    result = ray.get(future)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2624, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=29098, ip=172.28.0.12, actor_id=d21499668ad7b5877926ced001000000, repr=train)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 342, in train\n",
            "    raise skipped from exception_cause(skipped)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/_internal/util.py\", line 88, in run\n",
            "    self._ret = self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 115, in <lambda>\n",
            "    training_func=lambda: self._trainable_func(self.config),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 332, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"<ipython-input-21-4cf143c8e7dd>\", line 13, in train\n",
            "AttributeError: 'dict' object has no attribute 'training_iteration'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial train_091b2_00015 started with configuration:\n",
            "+-------------------------------------------+\n",
            "| Trial train_091b2_00015 config            |\n",
            "+-------------------------------------------+\n",
            "| clip_param                            0.1 |\n",
            "| lambda                                  1 |\n",
            "| lr                                 0.0003 |\n",
            "| stop_iteration                         10 |\n",
            "+-------------------------------------------+\n",
            "\n",
            "Trial train_091b2_00015 errored after 0 iterations at 2024-01-07 11:08:56. Total running time: 49s\n",
            "Error file: /content/tune_results/train_2024-01-07_11-08-07/train_091b2_00015_15_clip_param=0.1000,lambda=1.0000,lr=0.0003_2024-01-07_11-08-07/error.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-01-07 11:08:58,088\tERROR tune_controller.py:1374 -- Trial task failed for trial train_091b2_00016\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
            "    result = ray.get(future)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2624, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=29103, ip=172.28.0.12, actor_id=fff4e46abfa33bb03160c4c401000000, repr=train)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 342, in train\n",
            "    raise skipped from exception_cause(skipped)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/_internal/util.py\", line 88, in run\n",
            "    self._ret = self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 115, in <lambda>\n",
            "    training_func=lambda: self._trainable_func(self.config),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 332, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"<ipython-input-21-4cf143c8e7dd>\", line 13, in train\n",
            "AttributeError: 'dict' object has no attribute 'training_iteration'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial train_091b2_00016 started with configuration:\n",
            "+-------------------------------------------+\n",
            "| Trial train_091b2_00016 config            |\n",
            "+-------------------------------------------+\n",
            "| clip_param                            0.2 |\n",
            "| lambda                                  1 |\n",
            "| lr                                 0.0003 |\n",
            "| stop_iteration                         10 |\n",
            "+-------------------------------------------+\n",
            "\n",
            "Trial train_091b2_00016 errored after 0 iterations at 2024-01-07 11:08:58. Total running time: 50s\n",
            "Error file: /content/tune_results/train_2024-01-07_11-08-07/train_091b2_00016_16_clip_param=0.2000,lambda=1.0000,lr=0.0003_2024-01-07_11-08-13/error.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-01-07 11:09:01,000\tWARNING tune.py:186 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial status: 17 ERROR | 16 PENDING\n",
            "Current time: 2024-01-07 11:09:01. Total running time: 53s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/1 GPUs\n",
            "+-----------------------------------------------------------------+\n",
            "| Trial name          status       lambda     clip_param       lr |\n",
            "+-----------------------------------------------------------------+\n",
            "| train_091b2_00017   PENDING         1              0.3   0.0003 |\n",
            "| train_091b2_00018   PENDING         0.8            0.1   0.001  |\n",
            "| train_091b2_00019   PENDING         0.8            0.2   0.001  |\n",
            "| train_091b2_00020   PENDING         0.8            0.3   0.001  |\n",
            "| train_091b2_00021   PENDING         0.9            0.1   0.001  |\n",
            "| train_091b2_00022   PENDING         0.9            0.2   0.001  |\n",
            "| train_091b2_00023   PENDING         0.9            0.3   0.001  |\n",
            "| train_091b2_00024   PENDING         1              0.1   0.001  |\n",
            "| train_091b2_00025   PENDING         1              0.2   0.001  |\n",
            "| train_091b2_00026   PENDING         1              0.3   0.001  |\n",
            "| train_091b2_00027   PENDING         0.8            0.1   0.0001 |\n",
            "| train_091b2_00028   PENDING         0.8            0.2   0.0001 |\n",
            "| train_091b2_00029   PENDING         0.8            0.3   0.0001 |\n",
            "| train_091b2_00030   PENDING         0.9            0.1   0.0001 |\n",
            "| train_091b2_00031   PENDING         0.9            0.2   0.0001 |\n",
            "| train_091b2_00032   PENDING         0.9            0.3   0.0001 |\n",
            "| train_091b2_00000   ERROR           0.8            0.1   0.0001 |\n",
            "| train_091b2_00001   ERROR           0.8            0.2   0.0001 |\n",
            "| train_091b2_00002   ERROR           0.8            0.3   0.0001 |\n",
            "| train_091b2_00003   ERROR           0.9            0.1   0.0001 |\n",
            "| train_091b2_00004   ERROR           0.9            0.2   0.0001 |\n",
            "| train_091b2_00005   ERROR           0.9            0.3   0.0001 |\n",
            "| train_091b2_00006   ERROR           1              0.1   0.0001 |\n",
            "| train_091b2_00007   ERROR           1              0.2   0.0001 |\n",
            "| train_091b2_00008   ERROR           1              0.3   0.0001 |\n",
            "| train_091b2_00009   ERROR           0.8            0.1   0.0003 |\n",
            "| train_091b2_00010   ERROR           0.8            0.2   0.0003 |\n",
            "| train_091b2_00011   ERROR           0.8            0.3   0.0003 |\n",
            "| train_091b2_00012   ERROR           0.9            0.1   0.0003 |\n",
            "| train_091b2_00013   ERROR           0.9            0.2   0.0003 |\n",
            "| train_091b2_00014   ERROR           0.9            0.3   0.0003 |\n",
            "| train_091b2_00015   ERROR           1              0.1   0.0003 |\n",
            "| train_091b2_00016   ERROR           1              0.2   0.0003 |\n",
            "+-----------------------------------------------------------------+\n",
            "\n",
            "Number of errored trials: 17\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name            # failures   error file                                                                                                                                   |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_091b2_00000              1   /content/tune_results/train_2024-01-07_11-08-07/train_091b2_00000_0_clip_param=0.1000,lambda=0.8000,lr=0.0001_2024-01-07_11-08-07/error.txt  |\n",
            "| train_091b2_00001              1   /content/tune_results/train_2024-01-07_11-08-07/train_091b2_00001_1_clip_param=0.2000,lambda=0.8000,lr=0.0001_2024-01-07_11-08-07/error.txt  |\n",
            "| train_091b2_00002              1   /content/tune_results/train_2024-01-07_11-08-07/train_091b2_00002_2_clip_param=0.3000,lambda=0.8000,lr=0.0001_2024-01-07_11-08-07/error.txt  |\n",
            "| train_091b2_00003              1   /content/tune_results/train_2024-01-07_11-08-07/train_091b2_00003_3_clip_param=0.1000,lambda=0.9000,lr=0.0001_2024-01-07_11-08-07/error.txt  |\n",
            "| train_091b2_00004              1   /content/tune_results/train_2024-01-07_11-08-07/train_091b2_00004_4_clip_param=0.2000,lambda=0.9000,lr=0.0001_2024-01-07_11-08-07/error.txt  |\n",
            "| train_091b2_00005              1   /content/tune_results/train_2024-01-07_11-08-07/train_091b2_00005_5_clip_param=0.3000,lambda=0.9000,lr=0.0001_2024-01-07_11-08-07/error.txt  |\n",
            "| train_091b2_00006              1   /content/tune_results/train_2024-01-07_11-08-07/train_091b2_00006_6_clip_param=0.1000,lambda=1.0000,lr=0.0001_2024-01-07_11-08-07/error.txt  |\n",
            "| train_091b2_00007              1   /content/tune_results/train_2024-01-07_11-08-07/train_091b2_00007_7_clip_param=0.2000,lambda=1.0000,lr=0.0001_2024-01-07_11-08-07/error.txt  |\n",
            "| train_091b2_00008              1   /content/tune_results/train_2024-01-07_11-08-07/train_091b2_00008_8_clip_param=0.3000,lambda=1.0000,lr=0.0001_2024-01-07_11-08-07/error.txt  |\n",
            "| train_091b2_00009              1   /content/tune_results/train_2024-01-07_11-08-07/train_091b2_00009_9_clip_param=0.1000,lambda=0.8000,lr=0.0003_2024-01-07_11-08-07/error.txt  |\n",
            "| train_091b2_00010              1   /content/tune_results/train_2024-01-07_11-08-07/train_091b2_00010_10_clip_param=0.2000,lambda=0.8000,lr=0.0003_2024-01-07_11-08-07/error.txt |\n",
            "| train_091b2_00011              1   /content/tune_results/train_2024-01-07_11-08-07/train_091b2_00011_11_clip_param=0.3000,lambda=0.8000,lr=0.0003_2024-01-07_11-08-07/error.txt |\n",
            "| train_091b2_00012              1   /content/tune_results/train_2024-01-07_11-08-07/train_091b2_00012_12_clip_param=0.1000,lambda=0.9000,lr=0.0003_2024-01-07_11-08-07/error.txt |\n",
            "| train_091b2_00013              1   /content/tune_results/train_2024-01-07_11-08-07/train_091b2_00013_13_clip_param=0.2000,lambda=0.9000,lr=0.0003_2024-01-07_11-08-07/error.txt |\n",
            "| train_091b2_00014              1   /content/tune_results/train_2024-01-07_11-08-07/train_091b2_00014_14_clip_param=0.3000,lambda=0.9000,lr=0.0003_2024-01-07_11-08-07/error.txt |\n",
            "| train_091b2_00015              1   /content/tune_results/train_2024-01-07_11-08-07/train_091b2_00015_15_clip_param=0.1000,lambda=1.0000,lr=0.0003_2024-01-07_11-08-07/error.txt |\n",
            "| train_091b2_00016              1   /content/tune_results/train_2024-01-07_11-08-07/train_091b2_00016_16_clip_param=0.2000,lambda=1.0000,lr=0.0003_2024-01-07_11-08-13/error.txt |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-01-07 11:09:03,712\tERROR tune.py:1038 -- Trials did not complete: [train_091b2_00000, train_091b2_00001, train_091b2_00002, train_091b2_00003, train_091b2_00004, train_091b2_00005, train_091b2_00006, train_091b2_00007, train_091b2_00008, train_091b2_00009, train_091b2_00010, train_091b2_00011, train_091b2_00012, train_091b2_00013, train_091b2_00014, train_091b2_00015, train_091b2_00016]\n",
            "2024-01-07 11:09:03,724\tWARNING tune.py:1057 -- Experiment has been interrupted, but the most recent state was saved.\n",
            "Resume experiment with: tune.run(..., resume=True)\n",
            "2024-01-07 11:09:03,750\tWARNING experiment_analysis.py:193 -- Failed to fetch metrics for 16 trial(s):\n",
            "- train_091b2_00017: FileNotFoundError('Could not fetch metrics for train_091b2_00017: both result.json and progress.csv were not found at /content/tune_results/train_2024-01-07_11-08-07/train_091b2_00017_17_clip_param=0.3000,lambda=1.0000,lr=0.0003_2024-01-07_11-08-13')\n",
            "- train_091b2_00018: FileNotFoundError('Could not fetch metrics for train_091b2_00018: both result.json and progress.csv were not found at /content/tune_results/train_2024-01-07_11-08-07/train_091b2_00018_18_clip_param=0.1000,lambda=0.8000,lr=0.0010_2024-01-07_11-08-19')\n",
            "- train_091b2_00019: FileNotFoundError('Could not fetch metrics for train_091b2_00019: both result.json and progress.csv were not found at /content/tune_results/train_2024-01-07_11-08-07/train_091b2_00019_19_clip_param=0.2000,lambda=0.8000,lr=0.0010_2024-01-07_11-08-19')\n",
            "- train_091b2_00020: FileNotFoundError('Could not fetch metrics for train_091b2_00020: both result.json and progress.csv were not found at /content/tune_results/train_2024-01-07_11-08-07/train_091b2_00020_20_clip_param=0.3000,lambda=0.8000,lr=0.0010_2024-01-07_11-08-24')\n",
            "- train_091b2_00021: FileNotFoundError('Could not fetch metrics for train_091b2_00021: both result.json and progress.csv were not found at /content/tune_results/train_2024-01-07_11-08-07/train_091b2_00021_21_clip_param=0.1000,lambda=0.9000,lr=0.0010_2024-01-07_11-08-24')\n",
            "- train_091b2_00022: FileNotFoundError('Could not fetch metrics for train_091b2_00022: both result.json and progress.csv were not found at /content/tune_results/train_2024-01-07_11-08-07/train_091b2_00022_22_clip_param=0.2000,lambda=0.9000,lr=0.0010_2024-01-07_11-08-32')\n",
            "- train_091b2_00023: FileNotFoundError('Could not fetch metrics for train_091b2_00023: both result.json and progress.csv were not found at /content/tune_results/train_2024-01-07_11-08-07/train_091b2_00023_23_clip_param=0.3000,lambda=0.9000,lr=0.0010_2024-01-07_11-08-32')\n",
            "- train_091b2_00024: FileNotFoundError('Could not fetch metrics for train_091b2_00024: both result.json and progress.csv were not found at /content/tune_results/train_2024-01-07_11-08-07/train_091b2_00024_24_clip_param=0.1000,lambda=1.0000,lr=0.0010_2024-01-07_11-08-36')\n",
            "- train_091b2_00025: FileNotFoundError('Could not fetch metrics for train_091b2_00025: both result.json and progress.csv were not found at /content/tune_results/train_2024-01-07_11-08-07/train_091b2_00025_25_clip_param=0.2000,lambda=1.0000,lr=0.0010_2024-01-07_11-08-37')\n",
            "- train_091b2_00026: FileNotFoundError('Could not fetch metrics for train_091b2_00026: both result.json and progress.csv were not found at /content/tune_results/train_2024-01-07_11-08-07/train_091b2_00026_26_clip_param=0.3000,lambda=1.0000,lr=0.0010_2024-01-07_11-08-41')\n",
            "- train_091b2_00027: FileNotFoundError('Could not fetch metrics for train_091b2_00027: both result.json and progress.csv were not found at /content/tune_results/train_2024-01-07_11-08-07/train_091b2_00027_27_clip_param=0.1000,lambda=0.8000,lr=0.0001_2024-01-07_11-08-46')\n",
            "- train_091b2_00028: FileNotFoundError('Could not fetch metrics for train_091b2_00028: both result.json and progress.csv were not found at /content/tune_results/train_2024-01-07_11-08-07/train_091b2_00028_28_clip_param=0.2000,lambda=0.8000,lr=0.0001_2024-01-07_11-08-47')\n",
            "- train_091b2_00029: FileNotFoundError('Could not fetch metrics for train_091b2_00029: both result.json and progress.csv were not found at /content/tune_results/train_2024-01-07_11-08-07/train_091b2_00029_29_clip_param=0.3000,lambda=0.8000,lr=0.0001_2024-01-07_11-08-51')\n",
            "- train_091b2_00030: FileNotFoundError('Could not fetch metrics for train_091b2_00030: both result.json and progress.csv were not found at /content/tune_results/train_2024-01-07_11-08-07/train_091b2_00030_30_clip_param=0.1000,lambda=0.9000,lr=0.0001_2024-01-07_11-08-53')\n",
            "- train_091b2_00031: FileNotFoundError('Could not fetch metrics for train_091b2_00031: both result.json and progress.csv were not found at /content/tune_results/train_2024-01-07_11-08-07/train_091b2_00031_31_clip_param=0.2000,lambda=0.9000,lr=0.0001_2024-01-07_11-08-56')\n",
            "- train_091b2_00032: FileNotFoundError('Could not fetch metrics for train_091b2_00032: both result.json and progress.csv were not found at /content/tune_results/train_2024-01-07_11-08-07/train_091b2_00032_32_clip_param=0.3000,lambda=0.9000,lr=0.0001_2024-01-07_11-08-58')\n",
            "2024-01-07 11:09:03,753\tWARNING experiment_analysis.py:584 -- Could not find best trial. Did you pass the correct `metric` parameter?\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Best Hyperparameters: None\n"
          ]
        }
      ],
      "source": [
        "import ray\n",
        "from ray import tune\n",
        "from ray.tune import CLIReporter\n",
        "import os\n",
        "import gym\n",
        "\n",
        "def train(config):\n",
        "    env_name = \"LunarLander-v2\"\n",
        "    config[\"env\"] = env_name\n",
        "\n",
        "    stop_iteration = config.get(\"stop_iteration\", 100)  # Set a maximum number of training iterations\n",
        "    for i in range(stop_iteration):\n",
        "        result = config.training_iteration()\n",
        "        mean_reward = result[\"episode_reward_mean\"]\n",
        "\n",
        "        # Use ray.train.report() to report results\n",
        "        tune.report(mean_reward=mean_reward, training_iteration=i+1)\n",
        "\n",
        "        # Stopping criteria: Stop when mean_reward reaches 200\n",
        "        if mean_reward >= 0:\n",
        "            break\n",
        "\n",
        "config_space = {\n",
        "    \"lambda\": tune.grid_search([0.8, 0.9, 0.95]),\n",
        "    \"clip_param\": tune.grid_search([0.1, 0.2, 0.3]),\n",
        "    \"lr\": tune.grid_search([1e-4, 3e-4, 1e-3]),\n",
        "    \"stop_iteration\": 100,  # Number of training iterations\n",
        "}\n",
        "\n",
        "reporter = CLIReporter(metric_columns=[\"mean_reward\", \"training_iteration\"])\n",
        "\n",
        "ray.init(num_cpus=2, num_gpus=1, ignore_reinit_error=True)\n",
        "\n",
        "# Use an absolute path for local_dir\n",
        "absolute_path = os.path.abspath(\"./tune_results\")\n",
        "\n",
        "analysis = tune.run(\n",
        "    train,\n",
        "    config=config_space,\n",
        "    num_samples=3,\n",
        "    local_dir=absolute_path,\n",
        "    progress_reporter=reporter,\n",
        ")\n",
        "\n",
        "\n",
        "# Get best hyperparameters\n",
        "best_config = analysis.get_best_config(metric=\"mean_reward\", mode=\"max\")\n",
        "print(\"Best Hyperparameters:\", best_config)\n",
        "\n",
        "ray.shutdown()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FOVfnyfEzku"
      },
      "source": [
        "# Adding less fuel consumption objective"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A47ksRF6E6XI"
      },
      "source": [
        "Here is a modified reward function adding penalties for using to much fuel. How the model will react to changes ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "0rETZMMnE5ad"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def basic_reward(state, action, next_state):\n",
        "    # Reward for descending gently\n",
        "    descent_reward = 1.0 - abs(next_state[1])\n",
        "\n",
        "    # Reward for aligning with the landing pad\n",
        "    alignment_reward = 1.0 - abs(next_state[4])\n",
        "\n",
        "    # Penalty for fuel usage (negative reward)\n",
        "    fuel_penalty = -0.1 * np.linalg.norm(action)\n",
        "\n",
        "    # Combine the reward components\n",
        "    total_reward = descent_reward + alignment_reward + fuel_penalty\n",
        "\n",
        "    return total_reward\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4S_qWKc255YI"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "import ray\n",
        "from ray import tune\n",
        "\n",
        "# Define a custom reward function with adjusted shaping\n",
        "def complex_reward(state, action, next_state, reward, done):\n",
        "    # Extract relevant information from the state\n",
        "    position_x = state[0]\n",
        "    position_y = state[1]\n",
        "    velocity_x = state[2]\n",
        "    velocity_y = state[3]\n",
        "    angle = state[4]\n",
        "    angular_velocity = state[5]\n",
        "    left_leg_contact = state[6]\n",
        "    right_leg_contact = state[7]\n",
        "\n",
        "    # Penalize for using engine thrust (negative reward)\n",
        "    fuel_penalty = -0.1 * abs(action[0])\n",
        "\n",
        "    # Reward for moving towards the landing pad\n",
        "    landing_reward = 10.0 * (position_x + 0.5)\n",
        "\n",
        "    # Additional rewards for a safe landing and less fuel consumption\n",
        "    if abs(position_x) < 0.05 and abs(position_y) < 0.05 and velocity_y <= 0.0:\n",
        "        landing_reward += 100.0\n",
        "        fuel_penalty -= 0.1  # Encourage less fuel consumption during safe landing\n",
        "\n",
        "    # Combine rewards\n",
        "    total_reward = reward + fuel_penalty + landing_reward\n",
        "\n",
        "    return total_reward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-WeYWvfiDcA",
        "outputId": "99a3d199-531e-49b5-ca17-3e545e617f8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-01-07 11:58:12,172\tINFO worker.py:1724 -- Started a local Ray instance.\n",
            "2024-01-07 11:58:13,782\tINFO tune.py:592 -- [output] This will use the new output engine with verbosity 2. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------------+\n",
            "| Configuration for experiment     my_experiment         |\n",
            "+--------------------------------------------------------+\n",
            "| Search algorithm                 BasicVariantGenerator |\n",
            "| Scheduler                        FIFOScheduler         |\n",
            "| Number of trials                 1                     |\n",
            "+--------------------------------------------------------+\n",
            "\n",
            "View detailed results here: /root/ray_results/my_experiment\n",
            "To visualize your results with TensorBoard, run: `tensorboard --logdir /root/ray_results/my_experiment`\n",
            "\n",
            "Trial status: 1 PENDING\n",
            "Current time: 2024-01-07 11:58:14. Total running time: 0s\n",
            "Logical resource usage: 0/2 CPUs, 0/1 GPUs\n",
            "+-------------------------------------------+\n",
            "| Trial name                       status   |\n",
            "+-------------------------------------------+\n",
            "| PPO_LunarLander-v2_0934b_00000   PENDING  |\n",
            "+-------------------------------------------+\n",
            "\n",
            "Trial PPO_LunarLander-v2_0934b_00000 started with configuration:\n",
            "+----------------------------------------------------------------------+\n",
            "| Trial PPO_LunarLander-v2_0934b_00000 config                          |\n",
            "+----------------------------------------------------------------------+\n",
            "| clip_param                                                       0.1 |\n",
            "| env                                                   LunarLander-v2 |\n",
            "| framework                                                         tf |\n",
            "| gamma                                                           0.99 |\n",
            "| lambda                                                           0.9 |\n",
            "| lr                                                           0.00005 |\n",
            "| num_iterations                                                100000 |\n",
            "| num_workers                                                        1 |\n",
            "| reward_fn                                       ...t 0x7e88102a1f30> |\n",
            "| sgd_minibatch_size                                               256 |\n",
            "| train_batch_size                                                1000 |\n",
            "+----------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(PPO pid=44082)\u001b[0m Trainable.setup took 11.791 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
            "\u001b[36m(PPO pid=44082)\u001b[0m Install gputil for GPU system monitoring.\n",
            "\u001b[36m(PPO pid=44082)\u001b[0m 2024-01-07 11:58:38,223\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.execution.train_ops.multi_gpu_train_one_step` has been deprecated. This will raise an error in the future!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial PPO_LunarLander-v2_0934b_00000 finished iteration 1 at 2024-01-07 11:58:39. Total running time: 25s\n",
            "+----------------------------------------------------------+\n",
            "| Trial PPO_LunarLander-v2_0934b_00000 result              |\n",
            "+----------------------------------------------------------+\n",
            "| episodes_total                                        11 |\n",
            "| num_env_steps_sampled                               1000 |\n",
            "| num_env_steps_trained                               1000 |\n",
            "| sampler_results/episode_len_mean                      83 |\n",
            "| sampler_results/episode_reward_mean             -127.936 |\n",
            "+----------------------------------------------------------+\n",
            "\n",
            "Trial PPO_LunarLander-v2_0934b_00000 finished iteration 2 at 2024-01-07 11:58:41. Total running time: 27s\n",
            "+----------------------------------------------------------+\n",
            "| Trial PPO_LunarLander-v2_0934b_00000 result              |\n",
            "+----------------------------------------------------------+\n",
            "| episodes_total                                        22 |\n",
            "| num_env_steps_sampled                               2000 |\n",
            "| num_env_steps_trained                               2000 |\n",
            "| sampler_results/episode_len_mean                 89.0455 |\n",
            "| sampler_results/episode_reward_mean             -168.255 |\n",
            "+----------------------------------------------------------+\n",
            "\n",
            "Trial status: 1 RUNNING\n",
            "Current time: 2024-01-07 11:58:44. Total running time: 30s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/1 GPUs\n",
            "Current best trial: 0934b_00000 with episode_reward_mean=-168.2545903191963 and params={'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'LunarLander-v2', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'enable_connectors': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'validate_workers_after_construction': True, 'compress_observations': False, 'sampler_perf_stats_ema_coef': None, 'sample_async': -1, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7e8614212950>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 256, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'reward_fn': <function basic_reward at 0x7e86fdb7ee60>, 'num_iterations': 100000, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.9, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'tf', 'num_cpus_for_driver': 1, 'num_workers': 1}\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                       status       iter     total time (s)     ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| PPO_LunarLander-v2_0934b_00000   RUNNING         2             5.1537   2000   -168.255               -54.6947               -478.198              89.0455                     11 |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n",
            "Trial PPO_LunarLander-v2_0934b_00000 finished iteration 3 at 2024-01-07 11:58:44. Total running time: 30s\n",
            "+---------------------------------------------------------+\n",
            "| Trial PPO_LunarLander-v2_0934b_00000 result             |\n",
            "+---------------------------------------------------------+\n",
            "| episodes_total                                       32 |\n",
            "| num_env_steps_sampled                              3000 |\n",
            "| num_env_steps_trained                              3000 |\n",
            "| sampler_results/episode_len_mean                92.0312 |\n",
            "| sampler_results/episode_reward_mean             -166.34 |\n",
            "+---------------------------------------------------------+\n",
            "\n",
            "Trial PPO_LunarLander-v2_0934b_00000 finished iteration 4 at 2024-01-07 11:58:47. Total running time: 33s\n",
            "+----------------------------------------------------------+\n",
            "| Trial PPO_LunarLander-v2_0934b_00000 result              |\n",
            "+----------------------------------------------------------+\n",
            "| episodes_total                                        41 |\n",
            "| num_env_steps_sampled                               4000 |\n",
            "| num_env_steps_trained                               4000 |\n",
            "| sampler_results/episode_len_mean                 95.0732 |\n",
            "| sampler_results/episode_reward_mean             -157.593 |\n",
            "+----------------------------------------------------------+\n",
            "\n",
            "Trial PPO_LunarLander-v2_0934b_00000 finished iteration 5 at 2024-01-07 11:58:50. Total running time: 36s\n",
            "+----------------------------------------------------------+\n",
            "| Trial PPO_LunarLander-v2_0934b_00000 result              |\n",
            "+----------------------------------------------------------+\n",
            "| episodes_total                                        51 |\n",
            "| num_env_steps_sampled                               5000 |\n",
            "| num_env_steps_trained                               5000 |\n",
            "| sampler_results/episode_len_mean                 96.8824 |\n",
            "| sampler_results/episode_reward_mean             -167.124 |\n",
            "+----------------------------------------------------------+\n",
            "\n",
            "Trial PPO_LunarLander-v2_0934b_00000 finished iteration 6 at 2024-01-07 11:58:53. Total running time: 39s\n",
            "+---------------------------------------------------------+\n",
            "| Trial PPO_LunarLander-v2_0934b_00000 result             |\n",
            "+---------------------------------------------------------+\n",
            "| episodes_total                                       63 |\n",
            "| num_env_steps_sampled                              6000 |\n",
            "| num_env_steps_trained                              6000 |\n",
            "| sampler_results/episode_len_mean                95.1746 |\n",
            "| sampler_results/episode_reward_mean             -159.73 |\n",
            "+---------------------------------------------------------+\n",
            "\n",
            "Trial PPO_LunarLander-v2_0934b_00000 finished iteration 7 at 2024-01-07 11:58:55. Total running time: 41s\n",
            "+----------------------------------------------------------+\n",
            "| Trial PPO_LunarLander-v2_0934b_00000 result              |\n",
            "+----------------------------------------------------------+\n",
            "| episodes_total                                        72 |\n",
            "| num_env_steps_sampled                               7000 |\n",
            "| num_env_steps_trained                               7000 |\n",
            "| sampler_results/episode_len_mean                 96.4583 |\n",
            "| sampler_results/episode_reward_mean             -153.086 |\n",
            "+----------------------------------------------------------+\n",
            "\n",
            "Trial PPO_LunarLander-v2_0934b_00000 finished iteration 8 at 2024-01-07 11:58:58. Total running time: 44s\n",
            "+----------------------------------------------------------+\n",
            "| Trial PPO_LunarLander-v2_0934b_00000 result              |\n",
            "+----------------------------------------------------------+\n",
            "| episodes_total                                        80 |\n",
            "| num_env_steps_sampled                               8000 |\n",
            "| num_env_steps_trained                               8000 |\n",
            "| sampler_results/episode_len_mean                  98.675 |\n",
            "| sampler_results/episode_reward_mean             -151.616 |\n",
            "+----------------------------------------------------------+\n",
            "\n",
            "Trial PPO_LunarLander-v2_0934b_00000 finished iteration 9 at 2024-01-07 11:59:00. Total running time: 46s\n",
            "+----------------------------------------------------------+\n",
            "| Trial PPO_LunarLander-v2_0934b_00000 result              |\n",
            "+----------------------------------------------------------+\n",
            "| episodes_total                                        89 |\n",
            "| num_env_steps_sampled                               9000 |\n",
            "| num_env_steps_trained                               9000 |\n",
            "| sampler_results/episode_len_mean                 99.9101 |\n",
            "| sampler_results/episode_reward_mean             -149.866 |\n",
            "+----------------------------------------------------------+\n",
            "\n",
            "Trial PPO_LunarLander-v2_0934b_00000 finished iteration 10 at 2024-01-07 11:59:04. Total running time: 50s\n",
            "+---------------------------------------------------------+\n",
            "| Trial PPO_LunarLander-v2_0934b_00000 result             |\n",
            "+---------------------------------------------------------+\n",
            "| episodes_total                                       97 |\n",
            "| num_env_steps_sampled                             10000 |\n",
            "| num_env_steps_trained                             10000 |\n",
            "| sampler_results/episode_len_mean                102.619 |\n",
            "| sampler_results/episode_reward_mean             -146.74 |\n",
            "+---------------------------------------------------------+\n",
            "\n",
            "Trial PPO_LunarLander-v2_0934b_00000 finished iteration 11 at 2024-01-07 11:59:07. Total running time: 53s\n",
            "+----------------------------------------------------------+\n",
            "| Trial PPO_LunarLander-v2_0934b_00000 result              |\n",
            "+----------------------------------------------------------+\n",
            "| episodes_total                                       103 |\n",
            "| num_env_steps_sampled                              11000 |\n",
            "| num_env_steps_trained                              11000 |\n",
            "| sampler_results/episode_len_mean                   106.5 |\n",
            "| sampler_results/episode_reward_mean             -145.006 |\n",
            "+----------------------------------------------------------+\n",
            "\n",
            "Trial PPO_LunarLander-v2_0934b_00000 finished iteration 12 at 2024-01-07 11:59:09. Total running time: 55s\n",
            "+----------------------------------------------------------+\n",
            "| Trial PPO_LunarLander-v2_0934b_00000 result              |\n",
            "+----------------------------------------------------------+\n",
            "| episodes_total                                       109 |\n",
            "| num_env_steps_sampled                              12000 |\n",
            "| num_env_steps_trained                              12000 |\n",
            "| sampler_results/episode_len_mean                  111.06 |\n",
            "| sampler_results/episode_reward_mean             -144.773 |\n",
            "+----------------------------------------------------------+\n",
            "\n",
            "Trial PPO_LunarLander-v2_0934b_00000 finished iteration 13 at 2024-01-07 11:59:11. Total running time: 58s\n",
            "+----------------------------------------------------------+\n",
            "| Trial PPO_LunarLander-v2_0934b_00000 result              |\n",
            "+----------------------------------------------------------+\n",
            "| episodes_total                                       115 |\n",
            "| num_env_steps_sampled                              13000 |\n",
            "| num_env_steps_trained                              13000 |\n",
            "| sampler_results/episode_len_mean                  116.07 |\n",
            "| sampler_results/episode_reward_mean             -142.716 |\n",
            "+----------------------------------------------------------+\n",
            "\n",
            "Trial status: 1 RUNNING\n",
            "Current time: 2024-01-07 11:59:14. Total running time: 1min 0s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/1 GPUs\n",
            "Current best trial: 0934b_00000 with episode_reward_mean=-142.71620803213148 and params={'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'LunarLander-v2', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'enable_connectors': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'validate_workers_after_construction': True, 'compress_observations': False, 'sampler_perf_stats_ema_coef': None, 'sample_async': -1, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7e8614212950>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 256, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'reward_fn': <function basic_reward at 0x7e86fdb7ee60>, 'num_iterations': 100000, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.9, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'tf', 'num_cpus_for_driver': 1, 'num_workers': 1}\n",
            "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                       status       iter     total time (s)      ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter |\n",
            "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| PPO_LunarLander-v2_0934b_00000   RUNNING        13            34.9151   13000   -142.716                22.6119                -371.74               116.07                      6 |\n",
            "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n",
            "Trial PPO_LunarLander-v2_0934b_00000 finished iteration 14 at 2024-01-07 11:59:14. Total running time: 1min 0s\n",
            "+----------------------------------------------------------+\n",
            "| Trial PPO_LunarLander-v2_0934b_00000 result              |\n",
            "+----------------------------------------------------------+\n",
            "| episodes_total                                       122 |\n",
            "| num_env_steps_sampled                              14000 |\n",
            "| num_env_steps_trained                              14000 |\n",
            "| sampler_results/episode_len_mean                  119.76 |\n",
            "| sampler_results/episode_reward_mean             -137.691 |\n",
            "+----------------------------------------------------------+\n",
            "\n",
            "Trial PPO_LunarLander-v2_0934b_00000 finished iteration 15 at 2024-01-07 11:59:18. Total running time: 1min 4s\n",
            "+----------------------------------------------------------+\n",
            "| Trial PPO_LunarLander-v2_0934b_00000 result              |\n",
            "+----------------------------------------------------------+\n",
            "| episodes_total                                       127 |\n",
            "| num_env_steps_sampled                              15000 |\n",
            "| num_env_steps_trained                              15000 |\n",
            "| sampler_results/episode_len_mean                  125.57 |\n",
            "| sampler_results/episode_reward_mean             -139.762 |\n",
            "+----------------------------------------------------------+\n",
            "\n",
            "Trial PPO_LunarLander-v2_0934b_00000 finished iteration 16 at 2024-01-07 11:59:20. Total running time: 1min 7s\n",
            "+----------------------------------------------------------+\n",
            "| Trial PPO_LunarLander-v2_0934b_00000 result              |\n",
            "+----------------------------------------------------------+\n",
            "| episodes_total                                       132 |\n",
            "| num_env_steps_sampled                              16000 |\n",
            "| num_env_steps_trained                              16000 |\n",
            "| sampler_results/episode_len_mean                  128.98 |\n",
            "| sampler_results/episode_reward_mean             -139.942 |\n",
            "+----------------------------------------------------------+\n",
            "\n",
            "Trial PPO_LunarLander-v2_0934b_00000 finished iteration 17 at 2024-01-07 11:59:23. Total running time: 1min 9s\n",
            "+----------------------------------------------------------+\n",
            "| Trial PPO_LunarLander-v2_0934b_00000 result              |\n",
            "+----------------------------------------------------------+\n",
            "| episodes_total                                       139 |\n",
            "| num_env_steps_sampled                              17000 |\n",
            "| num_env_steps_trained                              17000 |\n",
            "| sampler_results/episode_len_mean                  133.19 |\n",
            "| sampler_results/episode_reward_mean             -140.433 |\n",
            "+----------------------------------------------------------+\n",
            "\n",
            "Trial PPO_LunarLander-v2_0934b_00000 finished iteration 18 at 2024-01-07 11:59:25. Total running time: 1min 11s\n",
            "+----------------------------------------------------------+\n",
            "| Trial PPO_LunarLander-v2_0934b_00000 result              |\n",
            "+----------------------------------------------------------+\n",
            "| episodes_total                                       145 |\n",
            "| num_env_steps_sampled                              18000 |\n",
            "| num_env_steps_trained                              18000 |\n",
            "| sampler_results/episode_len_mean                  136.07 |\n",
            "| sampler_results/episode_reward_mean             -137.741 |\n",
            "+----------------------------------------------------------+\n",
            "\n",
            "Trial PPO_LunarLander-v2_0934b_00000 finished iteration 19 at 2024-01-07 11:59:28. Total running time: 1min 14s\n",
            "+----------------------------------------------------------+\n",
            "| Trial PPO_LunarLander-v2_0934b_00000 result              |\n",
            "+----------------------------------------------------------+\n",
            "| episodes_total                                       150 |\n",
            "| num_env_steps_sampled                              19000 |\n",
            "| num_env_steps_trained                              19000 |\n",
            "| sampler_results/episode_len_mean                  140.43 |\n",
            "| sampler_results/episode_reward_mean             -138.281 |\n",
            "+----------------------------------------------------------+\n",
            "\n",
            "Trial PPO_LunarLander-v2_0934b_00000 finished iteration 20 at 2024-01-07 11:59:32. Total running time: 1min 18s\n",
            "+----------------------------------------------------------+\n",
            "| Trial PPO_LunarLander-v2_0934b_00000 result              |\n",
            "+----------------------------------------------------------+\n",
            "| episodes_total                                       154 |\n",
            "| num_env_steps_sampled                              20000 |\n",
            "| num_env_steps_trained                              20000 |\n",
            "| sampler_results/episode_len_mean                  144.98 |\n",
            "| sampler_results/episode_reward_mean             -137.737 |\n",
            "+----------------------------------------------------------+\n",
            "\n",
            "Trial PPO_LunarLander-v2_0934b_00000 finished iteration 21 at 2024-01-07 11:59:34. Total running time: 1min 21s\n",
            "+---------------------------------------------------------+\n",
            "| Trial PPO_LunarLander-v2_0934b_00000 result             |\n",
            "+---------------------------------------------------------+\n",
            "| episodes_total                                      159 |\n",
            "| num_env_steps_sampled                             21000 |\n",
            "| num_env_steps_trained                             21000 |\n",
            "| sampler_results/episode_len_mean                 152.83 |\n",
            "| sampler_results/episode_reward_mean             -141.01 |\n",
            "+---------------------------------------------------------+\n",
            "\n",
            "Trial PPO_LunarLander-v2_0934b_00000 finished iteration 22 at 2024-01-07 11:59:37. Total running time: 1min 23s\n",
            "+----------------------------------------------------------+\n",
            "| Trial PPO_LunarLander-v2_0934b_00000 result              |\n",
            "+----------------------------------------------------------+\n",
            "| episodes_total                                       163 |\n",
            "| num_env_steps_sampled                              22000 |\n",
            "| num_env_steps_trained                              22000 |\n",
            "| sampler_results/episode_len_mean                  158.35 |\n",
            "| sampler_results/episode_reward_mean             -143.711 |\n",
            "+----------------------------------------------------------+\n",
            "\n",
            "Trial PPO_LunarLander-v2_0934b_00000 finished iteration 23 at 2024-01-07 11:59:39. Total running time: 1min 25s\n",
            "+----------------------------------------------------------+\n",
            "| Trial PPO_LunarLander-v2_0934b_00000 result              |\n",
            "+----------------------------------------------------------+\n",
            "| episodes_total                                       168 |\n",
            "| num_env_steps_sampled                              23000 |\n",
            "| num_env_steps_trained                              23000 |\n",
            "| sampler_results/episode_len_mean                  164.08 |\n",
            "| sampler_results/episode_reward_mean             -147.333 |\n",
            "+----------------------------------------------------------+\n",
            "\n",
            "Trial PPO_LunarLander-v2_0934b_00000 finished iteration 24 at 2024-01-07 11:59:42. Total running time: 1min 28s\n",
            "+----------------------------------------------------------+\n",
            "| Trial PPO_LunarLander-v2_0934b_00000 result              |\n",
            "+----------------------------------------------------------+\n",
            "| episodes_total                                       171 |\n",
            "| num_env_steps_sampled                              24000 |\n",
            "| num_env_steps_trained                              24000 |\n",
            "| sampler_results/episode_len_mean                   168.9 |\n",
            "| sampler_results/episode_reward_mean             -149.073 |\n",
            "+----------------------------------------------------------+\n",
            "\n",
            "Trial status: 1 RUNNING\n",
            "Current time: 2024-01-07 11:59:44. Total running time: 1min 30s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/1 GPUs\n",
            "Current best trial: 0934b_00000 with episode_reward_mean=-149.07320639337865 and params={'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'LunarLander-v2', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'enable_connectors': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'validate_workers_after_construction': True, 'compress_observations': False, 'sampler_perf_stats_ema_coef': None, 'sample_async': -1, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7e8614212950>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 256, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'reward_fn': <function basic_reward at 0x7e8613efc280>, 'num_iterations': 100000, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.9, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'tf', 'num_cpus_for_driver': 1, 'num_workers': 1}\n",
            "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                       status       iter     total time (s)      ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter |\n",
            "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| PPO_LunarLander-v2_0934b_00000   RUNNING        24            64.7095   24000   -149.073                22.6119               -410.608                168.9                      3 |\n",
            "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n",
            "Trial PPO_LunarLander-v2_0934b_00000 finished iteration 25 at 2024-01-07 11:59:46. Total running time: 1min 32s\n",
            "+----------------------------------------------------------+\n",
            "| Trial PPO_LunarLander-v2_0934b_00000 result              |\n",
            "+----------------------------------------------------------+\n",
            "| episodes_total                                       176 |\n",
            "| num_env_steps_sampled                              25000 |\n",
            "| num_env_steps_trained                              25000 |\n",
            "| sampler_results/episode_len_mean                  173.24 |\n",
            "| sampler_results/episode_reward_mean             -156.288 |\n",
            "+----------------------------------------------------------+\n",
            "\n",
            "Trial PPO_LunarLander-v2_0934b_00000 finished iteration 26 at 2024-01-07 11:59:50. Total running time: 1min 36s\n",
            "+----------------------------------------------------------+\n",
            "| Trial PPO_LunarLander-v2_0934b_00000 result              |\n",
            "+----------------------------------------------------------+\n",
            "| episodes_total                                       180 |\n",
            "| num_env_steps_sampled                              26000 |\n",
            "| num_env_steps_trained                              26000 |\n",
            "| sampler_results/episode_len_mean                  179.32 |\n",
            "| sampler_results/episode_reward_mean             -157.314 |\n",
            "+----------------------------------------------------------+\n",
            "\n",
            "Trial PPO_LunarLander-v2_0934b_00000 finished iteration 27 at 2024-01-07 11:59:53. Total running time: 1min 39s\n",
            "+----------------------------------------------------------+\n",
            "| Trial PPO_LunarLander-v2_0934b_00000 result              |\n",
            "+----------------------------------------------------------+\n",
            "| episodes_total                                       185 |\n",
            "| num_env_steps_sampled                              27000 |\n",
            "| num_env_steps_trained                              27000 |\n",
            "| sampler_results/episode_len_mean                  184.71 |\n",
            "| sampler_results/episode_reward_mean             -153.442 |\n",
            "+----------------------------------------------------------+\n",
            "\n",
            "Trial PPO_LunarLander-v2_0934b_00000 finished iteration 28 at 2024-01-07 11:59:58. Total running time: 1min 44s\n",
            "+----------------------------------------------------------+\n",
            "| Trial PPO_LunarLander-v2_0934b_00000 result              |\n",
            "+----------------------------------------------------------+\n",
            "| episodes_total                                       188 |\n",
            "| num_env_steps_sampled                              28000 |\n",
            "| num_env_steps_trained                              28000 |\n",
            "| sampler_results/episode_len_mean                  190.63 |\n",
            "| sampler_results/episode_reward_mean             -155.816 |\n",
            "+----------------------------------------------------------+\n",
            "\n",
            "Trial PPO_LunarLander-v2_0934b_00000 finished iteration 29 at 2024-01-07 12:00:02. Total running time: 1min 48s\n",
            "+----------------------------------------------------------+\n",
            "| Trial PPO_LunarLander-v2_0934b_00000 result              |\n",
            "+----------------------------------------------------------+\n",
            "| episodes_total                                       192 |\n",
            "| num_env_steps_sampled                              29000 |\n",
            "| num_env_steps_trained                              29000 |\n",
            "| sampler_results/episode_len_mean                  195.11 |\n",
            "| sampler_results/episode_reward_mean             -158.302 |\n",
            "+----------------------------------------------------------+\n",
            "\n",
            "Trial PPO_LunarLander-v2_0934b_00000 finished iteration 30 at 2024-01-07 12:00:05. Total running time: 1min 51s\n",
            "+----------------------------------------------------------+\n",
            "| Trial PPO_LunarLander-v2_0934b_00000 result              |\n",
            "+----------------------------------------------------------+\n",
            "| episodes_total                                       193 |\n",
            "| num_env_steps_sampled                              30000 |\n",
            "| num_env_steps_trained                              30000 |\n",
            "| sampler_results/episode_len_mean                     196 |\n",
            "| sampler_results/episode_reward_mean             -157.225 |\n",
            "+----------------------------------------------------------+\n",
            "\n",
            "Trial PPO_LunarLander-v2_0934b_00000 finished iteration 31 at 2024-01-07 12:00:07. Total running time: 1min 53s\n",
            "+----------------------------------------------------------+\n",
            "| Trial PPO_LunarLander-v2_0934b_00000 result              |\n",
            "+----------------------------------------------------------+\n",
            "| episodes_total                                       197 |\n",
            "| num_env_steps_sampled                              31000 |\n",
            "| num_env_steps_trained                              31000 |\n",
            "| sampler_results/episode_len_mean                  207.81 |\n",
            "| sampler_results/episode_reward_mean             -161.979 |\n",
            "+----------------------------------------------------------+\n",
            "\n",
            "Trial PPO_LunarLander-v2_0934b_00000 finished iteration 32 at 2024-01-07 12:00:10. Total running time: 1min 56s\n",
            "+----------------------------------------------------------+\n",
            "| Trial PPO_LunarLander-v2_0934b_00000 result              |\n",
            "+----------------------------------------------------------+\n",
            "| episodes_total                                       201 |\n",
            "| num_env_steps_sampled                              32000 |\n",
            "| num_env_steps_trained                              32000 |\n",
            "| sampler_results/episode_len_mean                  213.83 |\n",
            "| sampler_results/episode_reward_mean             -164.835 |\n",
            "+----------------------------------------------------------+\n",
            "\n",
            "Trial PPO_LunarLander-v2_0934b_00000 finished iteration 33 at 2024-01-07 12:00:12. Total running time: 1min 58s\n",
            "+----------------------------------------------------------+\n",
            "| Trial PPO_LunarLander-v2_0934b_00000 result              |\n",
            "+----------------------------------------------------------+\n",
            "| episodes_total                                       205 |\n",
            "| num_env_steps_sampled                              33000 |\n",
            "| num_env_steps_trained                              33000 |\n",
            "| sampler_results/episode_len_mean                  216.99 |\n",
            "| sampler_results/episode_reward_mean             -166.188 |\n",
            "+----------------------------------------------------------+\n",
            "\n",
            "Trial status: 1 RUNNING\n",
            "Current time: 2024-01-07 12:00:14. Total running time: 2min 0s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/1 GPUs\n",
            "Current best trial: 0934b_00000 with episode_reward_mean=-166.18778892042405 and params={'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'LunarLander-v2', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'enable_connectors': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'validate_workers_after_construction': True, 'compress_observations': False, 'sampler_perf_stats_ema_coef': None, 'sample_async': -1, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7e8614212950>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 256, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'reward_fn': <function basic_reward at 0x7e86126317e0>, 'num_iterations': 100000, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.9, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'tf', 'num_cpus_for_driver': 1, 'num_workers': 1}\n",
            "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                       status       iter     total time (s)      ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter |\n",
            "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| PPO_LunarLander-v2_0934b_00000   RUNNING        33            94.4372   33000   -166.188                 20.279               -410.608               216.99                      4 |\n",
            "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-01-07 12:00:15,539\tWARNING tune.py:186 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 RUNNING\n",
            "Current time: 2024-01-07 12:00:15. Total running time: 2min 1s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/1 GPUs\n",
            "Current best trial: 0934b_00000 with episode_reward_mean=-166.18778892042405 and params={'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'LunarLander-v2', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'enable_connectors': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'validate_workers_after_construction': True, 'compress_observations': False, 'sampler_perf_stats_ema_coef': None, 'sample_async': -1, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7e8614212950>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 256, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'reward_fn': <function basic_reward at 0x7e86126317e0>, 'num_iterations': 100000, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.9, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'tf', 'num_cpus_for_driver': 1, 'num_workers': 1}\n",
            "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                       status       iter     total time (s)      ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter |\n",
            "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| PPO_LunarLander-v2_0934b_00000   RUNNING        33            94.4372   33000   -166.188                 20.279               -410.608               216.99                      4 |\n",
            "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-01-07 12:00:16,517\tWARNING tune.py:1057 -- Experiment has been interrupted, but the most recent state was saved.\n",
            "Resume experiment with: tune.run(..., resume=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Launch training in discrete space, using best hyperparams and custom reward\n",
        "ray.shutdown()\n",
        "ray.init(num_cpus=2, num_gpus=1, ignore_reinit_error=True)\n",
        "res = train_ppo('LunarLander-v2', reward_fn=basic_reward, lr=5e-5, lbd=0.9, clip_param=0.1)\n",
        "ray.shutdown()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFvrRt8unUKe"
      },
      "outputs": [],
      "source": [
        "analyze_and_plot(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WT7VrPe37WXM"
      },
      "source": [
        "# Continuous env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "qGdhc-8N7ZDn",
        "outputId": "91b83938-476d-4e06-d629-cf1ff29dc15c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-01-07 11:50:37,829\tINFO worker.py:1724 -- Started a local Ray instance.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_ppo' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-1b3e930a4306>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_cpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_gpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_reinit_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mcontinuous_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_ppo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcomplex_reward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlbd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip_param\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_ppo' is not defined"
          ]
        }
      ],
      "source": [
        "# We just change env\n",
        "import ray\n",
        "env=\"LunarLanderContinuous-v2\"\n",
        "ray.shutdown()\n",
        "ray.init(num_cpus=2, num_gpus=1, ignore_reinit_error=True)\n",
        "continuous_res = train_ppo(env_name=env, reward_fn=complex_reward, lr=1e-4, lbd=0.9, clip_param=0.2)\n",
        "ray.shutdown()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "analyze_and_plot(continuous_res)"
      ],
      "metadata": {
        "id": "yfXbAQolv81N"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMooChEyo8AECgNYb+SoBw3",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}